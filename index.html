<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN""http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">

<head>
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-WCTVDFFNBW"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-WCTVDFFNBW');
    </script>
    <title>NODEO CVPR 2022</title>
    <!-- Fonts and stuff -->
    <link href='https://fonts.googleapis.com/css?family=Source+Sans+Pro:400italic,700italic,800italic,400,700,800'
          rel='stylesheet' type='text/css'/>
    <link rel="stylesheet" type="text/css" href="css/project.css" media="screen"/>
    <link rel="stylesheet" type="text/css" media="screen" href="css/iconize.css"/>

    <!-- ðŸš¨ REQUIRED: Web Components polyfill to support Edge and Firefox < 63 -->
    <script src="https://unpkg.com/@webcomponents/webcomponentsjs@2.1.3/webcomponents-loader.js"></script>

    <!-- ðŸ’ OPTIONAL: Intersection Observer polyfill for better performance in Safari and IE11 -->
    <script src="https://unpkg.com/intersection-observer@0.5.1/intersection-observer.js"></script>

    <!-- ðŸ’ OPTIONAL: Resize Observer polyfill improves resize behavior in non-Chrome browsers -->
    <script src="https://unpkg.com/resize-observer-polyfill@1.5.1/dist/ResizeObserver.js"></script>


</head>

<body>
<div id="content">
    <div class="section logos">
        <a href="https://picsl.upenn.edu/" target="_blank"><img width="5%" src="./images/picsl.png"></a>
        <a href="https://www.grasp.upenn.edu" target="_blank"><img width="25%" src="./images/grasp.svg"></a>
    </div>

    <div class="section head">
        <h1>NODEO: A Neural Ordinary Differential Equation Based Optimization Framework for Deformable Image
            Registration</h1>

        <div class="authors">
            <a href="https://yifannnwu.github.io/" target="_blank" class="textLink">Yifan Wu*</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
            <a href="https://www.jiahaoz.com/" target="_blank" class="textLink">Tom Z. Jiahao*</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
            <a href="https://scholar.google.com/citations?user=TAnhOEsAAAAJ&hl=en" target="_blank" class="textLink">Jiancong
                Wang</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
            <a href="https://www.med.upenn.edu/apps/faculty/index.php/g275/p2693923" target="_blank" class="textLink">Paul
                A.
                Yushkevich</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
            <a href="https://www.grasp.upenn.edu/people/ani-hsieh/" target="_blank" class="textLink">M. Ami Hsieh</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
            <a href="https://www.med.upenn.edu/apps/faculty/index.php/g275/p10656" target="_blank" class="textLink">James
                C. Gee</a>&nbsp;&nbsp;&nbsp;&nbsp;
        </div>

        <div class="affiliations">
            <a href="https://www.cis.upenn.edu/" target="_blank">University of Pennsylvania</a>&nbsp;&nbsp;
        </div>

        <div class="venue"><a href="https://cvpr2022.thecvf.com/" target="_blank">CVPR 2022</a>
        </div>
    </div>

    <div id="content-inner">
        <div class="section abstract">

            <div class="section demo">
                <center>
                    <img src="./images/demo.png" width=80%>
                </center>
            </div>

            <div class="section downloads">
                <center>
                    <ul>
                        <li class="grid">
                            <div class="griditem">
                                <a href="pub/cvpr2022_NODEO_paper.pdf" target="_blank"
                                   class="imageLink"><img src="images/paper_thumb.png"></a><br>
                                Paper<br><a href="pub/cvpr2022_NODEO_paper.pdf"
                                            target="_blank">PDF</a>
                            </div>
                        </li>

                        <li class="grid">
                            <div class="griditem">
                                <a href="pub/cvpr2022_NODEO_supp.pdf" target="_blank"
                                   class="imageLink"><img src="images/supp_thumb.png"></a><br>
                                Supp<br><a href="pub/cvpr2022_NODEO_supp.pdf"
                                           target="_blank">PDF</a>
                            </div>
                        </li>

                        <li class="grid">
                            <div class="griditem">
                                <a href="pub/cvpr2022_NODEO_poster.pdf" target="_blank"
                                   class="imageLink"><img src="images/poster_thumb.png"></a><br>
                                Poster<br><a href="pub/cvpr2022_NODEO_poster.pdf"
                                             target="_blank">PDF</a>
                            </div>
                        </li>

                        <li class="grid">
                            <div class="griditem">
                                <a target="_blank" class="imageLink">
                                    <img src="images/code.png">
                                </a><br>
                                Code<br>
                                <a href="https://github.com/yifannnwu/NODEO-DIR" target="_blank">Github</a>
                            </div>
                        </li>
                    </ul>
                </center>
            </div>


            <div class="section abstract">
                <h2>Abstract</h2>
                <p>
                    Deformable image registration (DIR), aiming to find spatial correspondence between images, is one of
                    the most critical
                    problems in the domain of medical image analysis.
                    In this paper, we present a novel, generic, and accurate diffeomorphic image registration framework
                    that utilizes neural ordinary differential equations (NODEs).
                    We model each voxel as a moving particle and consider the set of all voxels in a 3D image as a
                    high-dimensional dynamical system whose trajectory determines the targeted deformation field.
                    Our method leverages deep neural networks for their expressive power in modeling dynamical systems,
                    and simultaneously optimizes for a dynamical system between the image pairs and the corresponding
                    transformation.
                    Our formulation allows various constraints to be imposed along the transformation to maintain
                    desired regularities.
                    Our experiment results show that our method outperforms the benchmarks under various metrics.
                    Additionally, we demonstrate the feasibility to expand our framework to register multiple image sets
                    using a unified form of transformation, which could possibly serve a wider range of applications.
                </p>
            </div>

            <div class="section abstract">
                <h2>Overview Video</h2>
                <center>
                    <iframe width="720" height="405"
                            src="https://www.youtube.com/embed/rOQjJYEElH0"
                            frameborder="0" webkitallowfullscreen mozallowfullscreen allowfullscreen>
                    </iframe>
                </center>
            </div>


            <br/><br/><br/>


            <div class="section list">
                <h2>Citation</h2>
                <div class="section bibtex">
                    <center>
                            <pre>@InProceedings{Wu_2022_CVPR,
    author    = {Wu, Yifan and Jiahao, Tom Z. and Wang, Jiancong and Yushkevich, Paul A. and Hsieh, M. Ani and Gee, James C.},
    title     = {NODEO: A Neural Ordinary Differential Equation Based Optimization Framework for Deformable Image Registration},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2022},
    pages     = {20804-20813}
}</pre>
                    </center>
                </div>
            </div>
        </div>
    </div>
</div>
</div>
</body>

</html>
